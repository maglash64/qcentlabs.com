<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Machine Learning on Microcontrollers. | qcentlabs</title><script async src="https://www.googletagmanager.com/gtag/js?id=G-PWDYJX7Y6B"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-PWDYJX7Y6B")</script><meta name=keywords content><meta name=description content="The Rise of Machine(s) &ldquo;The AI revolution in 2023 brought transformative changes to industries and daily life. Intelligent automation and advanced algorithms improved efficiency in manufacturing, healthcare, finance, and transportation. Natural language processing has led to the emergence of sophisticated voice assistants. Breakthroughs in image recognition and sentiment analysis revolutionised fields like autonomous vehicles, cybersecurity, and personalised marketing.&rdquo;
Well, I didn&rsquo;t write any of it, ChatGPT did.
So today we are going to explore if we can take advantage of machine learning to help build better embedded systems."><meta name=author content="magalsh64"><link rel=canonical href=http://qcentlabs.com/posts/ml_on_mcu/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css integrity="sha256-yIlj/i15RiAA/Q+xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.b95bacdc39e37a332a9f883b1e78be4abc1fdca2bc1f2641f55e3cd3dabd4d61.js integrity="sha256-uVus3DnjejMqn4g7Hni+Srwf3KK8HyZB9V4809q9TWE=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=http://qcentlabs.com/logo.png><link rel=icon type=image/png sizes=16x16 href=http://qcentlabs.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://qcentlabs.com/favicon-32x32.png><link rel=apple-touch-icon href=http://qcentlabs.com/logo.png><link rel=mask-icon href=http://qcentlabs.com/logo.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.112.7"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Machine Learning on Microcontrollers."><meta property="og:description" content="The Rise of Machine(s) &ldquo;The AI revolution in 2023 brought transformative changes to industries and daily life. Intelligent automation and advanced algorithms improved efficiency in manufacturing, healthcare, finance, and transportation. Natural language processing has led to the emergence of sophisticated voice assistants. Breakthroughs in image recognition and sentiment analysis revolutionised fields like autonomous vehicles, cybersecurity, and personalised marketing.&rdquo;
Well, I didn&rsquo;t write any of it, ChatGPT did.
So today we are going to explore if we can take advantage of machine learning to help build better embedded systems."><meta property="og:type" content="article"><meta property="og:url" content="http://qcentlabs.com/posts/ml_on_mcu/"><meta property="og:image" content="http://qcentlabs.com/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-03-02T04:21:11+05:30"><meta property="article:modified_time" content="2023-03-02T04:21:11+05:30"><meta property="og:site_name" content="qcentlabs"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://qcentlabs.com/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Machine Learning on Microcontrollers."><meta name=twitter:description content="The Rise of Machine(s) &ldquo;The AI revolution in 2023 brought transformative changes to industries and daily life. Intelligent automation and advanced algorithms improved efficiency in manufacturing, healthcare, finance, and transportation. Natural language processing has led to the emergence of sophisticated voice assistants. Breakthroughs in image recognition and sentiment analysis revolutionised fields like autonomous vehicles, cybersecurity, and personalised marketing.&rdquo;
Well, I didn&rsquo;t write any of it, ChatGPT did.
So today we are going to explore if we can take advantage of machine learning to help build better embedded systems."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://qcentlabs.com/posts/"},{"@type":"ListItem","position":2,"name":"Machine Learning on Microcontrollers.","item":"http://qcentlabs.com/posts/ml_on_mcu/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Machine Learning on Microcontrollers.","name":"Machine Learning on Microcontrollers.","description":"The Rise of Machine(s) \u0026ldquo;The AI revolution in 2023 brought transformative changes to industries and daily life. Intelligent automation and advanced algorithms improved efficiency in manufacturing, healthcare, finance, and transportation. Natural language processing has led to the emergence of sophisticated voice assistants. Breakthroughs in image recognition and sentiment analysis revolutionised fields like autonomous vehicles, cybersecurity, and personalised marketing.\u0026rdquo;\nWell, I didn\u0026rsquo;t write any of it, ChatGPT did.\nSo today we are going to explore if we can take advantage of machine learning to help build better embedded systems.","keywords":[],"articleBody":"The Rise of Machine(s) “The AI revolution in 2023 brought transformative changes to industries and daily life. Intelligent automation and advanced algorithms improved efficiency in manufacturing, healthcare, finance, and transportation. Natural language processing has led to the emergence of sophisticated voice assistants. Breakthroughs in image recognition and sentiment analysis revolutionised fields like autonomous vehicles, cybersecurity, and personalised marketing.”\nWell, I didn’t write any of it, ChatGPT did.\nSo today we are going to explore if we can take advantage of machine learning to help build better embedded systems.\nThis article is a continuation of a previous blog post in which, I hacked a synaptics touchpad.\nWe will use the touchpad as a base to get input for our neural network model.\nMachine learning is all about building and training models, which are essentially neural networks, to make predictions about what some input to the model might be.\nThis information (the prediction) can then be used to do various cool things.\n“Infrerence running on an $8 ARM Cortex-M7 MCU on a 28x28 image using LSTM model in under 7ms with more than 96% accuracy.”\nThe process of running ML models on a MCU can be divided into three parts:\nRecording data from various sensors to be used as the input to our network. Modelling and training the network with the recorded data. Deploying and running inference on the trained model using new real world data. Although some ML frameworks allow you to train the model on the MCU, most sane people will use a much powerful host computer or a web ML platform (Google Colab) to make and train the NN model.\nHow you run the inference of the trained model on the MCU depends on which ML framework you have chosen to use.\nSo, How is it done? For making and training the model, TensorFlow is used almost exclusively.\nI have used Keras, which gives us an easy to use python interface for accessing the TensorFlow library.\nYou can also use Google Colab Platform to make and train the model without having to deal with installing keras and tensorflow locally on your machine.\nFor running inference of the trained model, you have many options depending on which MCU you use.\nThere are quite a few ML frameworks available for MCUs, some manufacturers provide their owm ML frameworks for running models.\nSome popular ones are:\nTensorFlow Lite for Microcontrollers. (TFLM) AIfES DeepViewRT (NXP) STM32Cube.AI (STM) I have used both TFLM and AIfES, both are quite capable but TFLM has more features and support for more types of Ops but requires c++ support and is complex,\nAIfES on the other hand is quite easy to use and is written in C, but lacks features.\nAlso, you can directly import tflite models into TFLM, whereas AIfES requires you to extract weights and biases from your trained model and import them separately which is quite tedious.\nStep 1: Collect the data. The synaptics touchpad is the sensor that we will use to collect data for our ML demo.\nThe touchpad outputs data over PS/2 which is captured by our MCU.\nThe touchpad reports us with the absolute position of our finger when we touch it, we treat every position reported to us as a pixel coordinate in an image whose size is given by the resolution of our touchpad.\nWhenever a touch is reported we just fill the pixel coordinate with a value of 1 in our image array.\nThis specific model of touchpad has a resolution of near about 5600 x 4600 which is too big for even an average modern single GPU to run real time inference on let alone our MCU, so we need to scale down this resolution to something our MCU can handle.\nFor digit recognition, there is a well known dataset of small handwritten digits called MNIST dataset, we will use it as a starting point as it will provide us will a good large pre-tested dataset to train our network on.\nThe resolution of images in the MNIST dataset is 28x28, perfectly within the bounds of compute of our MCU, so we will scale down our touchpads 5600x4600 image to a 28x28 image.\nHere are some of the raw samples that i recorded from the touchpad:\nAs you can see, the raw points captured by our touchpad when downsampled to a 28x28 pose a bit of a problem for us.\nFirstly, sometimes you can see skipped pixels, these errors can be attributed to the downsampling process and also because the sample rate of our touchpad is not very high, and if we very quickly swipe our finger across the touchpad, we loose some samples. Secondly, these raw sample images have too little data in terms of pixel variations, the very narrow strokes of the touchpad samples are good for getting positioning data but do not resemble an actual pen stroke (something our MNIST dataset is based on.) Here is an example of what MNIST dataset containes:\nYou can see they do not match at all, If we train our NN on MNIST and then validate the NN on our raw samples, we will get very poor accuracy.\nThus we need to do a bit of pre-processing with our raw samples to make them a bit more like MNIST samples.\nIn we were to do this the right way, we would be collecting our own samples and making a large dataset for them as that would give us the best accuracy but that is a very time consuming task and thus we are cheating a bit here by using both MNIST which has over 60000 samples combined with some of our own raw samples.\nHere is our pre-processed version of touchpad data samples, this looks good enough for a demo.\nNot perfect, but would do the job. This pre-processing is done in real-time on MCU by applying a 3x3 averaging kernel.\nNow we collect and save a lot of these pre-processed images, our MCU simply sends them over USART as a C array and we have a program on host computer that writes this data to a CSV file which can then be used to train our neural network model.\nStep 2: Make and Train the model. I use google colab to test and train models.\nHere is the python script for the final version of the model which uses LSTM.\nimport tensorflow as tf from tensorflow import keras import numpy as np import pandas as pd import matplotlib.pyplot as plt print(\"using tf version: \", tf.__version__) dataset = pd.read_csv(\"drive/MyDrive/data/data_fat.csv\") x_train_custom = dataset.copy() y_train_custom = np.array(x_train_custom.pop('0')) x_train_custom = np.array(x_train_custom) x_train_custom = np.array(x_train_custom,dtype=np.float32) (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data() x_train = x_train.flatten() x_train = x_train.reshape(60000,784) x_train = x_train/255 x_train = np.array(x_train,dtype=np.float32) x_train = np.append(x_train,x_train_custom) y_train = np.append(y_train,y_train_custom) x_train = x_train.reshape(60542,784) dataset = pd.read_csv(\"drive/MyDrive/data/data_fat.csv\") x_test = dataset.copy() y_test = np.array(x_test.pop('0')) x_test = np.array(x_test) x_test = np.array(x_test,dtype=np.float32) model = tf.keras.Sequential() model.add(tf.keras.layers.Input(784,batch_size=1,dtype=tf.float32)) model.add(tf.keras.layers.Reshape((28,28))) model.add(tf.keras.layers.LSTM(20,return_sequences=True)) # model.add(tf.keras.layers.Conv2D(filters=8,kernel_size=3,padding='same',activation='relu')) # model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2),padding='same')) model.add(tf.keras.layers.Flatten()) model.add(tf.keras.layers.Dense(128)) model.add(tf.keras.layers.LeakyReLU(alpha=0.01)) model.add(tf.keras.layers.Dense(10)) model.add(tf.keras.layers.Activation('softmax')) loss_fn = keras.losses.SparseCategoricalCrossentropy() model.compile(optimizer='adam',loss=loss_fn,metrics=[\"accuracy\"]) model.fit(x_train,y_train,epochs=5,shuffle=True,validation_data=(x_test,y_test)) model.save(\"drive/MyDrive/data/tp.model\") def representative_dataset(): for data in x_train[:100]: yield [data.reshape(1, 28, 28)] converter = tf.lite.TFLiteConverter.from_keras_model(model) converter.optimizations = [tf.lite.Optimize.DEFAULT] converter.representative_dataset = representative_dataset converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8] converter.inference_input_type = tf.int8 converter.inference_output_type = tf.int8 tflite_model = converter.convert() # Save the model. with open('drive/MyDrive/data/model.tflite', 'wb') as f: f.write(tflite_model) Few things to note here,\nWe use google drive to host our custom dataset in a csv file, which we then read from and combine the custom data with the one from MNIST dataset.\nI tried 3 different models each with different pros and cons.\nFirst a simple FFN with 2-3 Dense layers, which was very fast to run inference on(5ms) and had small size but most of the time had overfitting issues which led to poor real-world accuracy.\nThen 1-2 Conv2D layers model was used instead of simple Dense layer, which offered high accuracy among real world input but was very slow to infer(0.5-3 seconds) and was huge in size (2-4MB).\nFinally a single LSTM layer was used which gave us high enough accuracy(96%) and was quicker to run inference on (~150ms) and had moderate size(400kB);\nAll of the above performance figures were on non optimized models running on FP32 data.\nHuge performance and memory gains were seen when converting the model to run on INT8 instead of FP32.\nThis is because TFLM can utilise the CMSIS-NN library which uses the native fixed point integer SIMD instructions(DSP extentions) present in Arm Cortex M7 and M4, which can help accelerate a lot of operations.\nLSTM models inference time decreased to 7ms from 150ms, and size became ~80k from ~330kb.\nAccuracy remained almost the same as humanly perceived,\nThe output of this training process gave us our model.tflite file which was then converted to a C array using xxd tool.\nxxd -i model.tflite \u003e model.h This header file was included into our MCU project.\nStep 3: Run inference on the trained model. A condensed version of the code that runs on the MCU is shown below.\n#include \"model.h\" const int tensor_arena_size = 32768 * 2; uint8_t tensor_arena[tensor_arena_size]; . . . //Initialise TFLM tflite::MicroErrorReporter micro_error_reporter; tflite::ErrorReporter *error_reporter = \u0026micro_error_reporter; const tflite::Model *model = tflite::GetModel(model_tflite); tflite::AllOpsResolver resolver; tflite::MicroInterpreter interpreter(model,resolver,tensor_arena,tensor_arena_size,error_reporter); interpreter.AllocateTensors(); . . . //somewhere in the code where PS/2 data is captured and pre-processed and stored in a array of floats . . . //Runs in a loop.. TfLiteTensor *input = interpreter.input(0); //load our pre-processed sample data into the tensor for(uint32_t i = 0; i \u003c 784; i++) input-\u003edata.int8[i] = (*((float*)img + i) * 255) - 128; //run the inference interpreter.Invoke(); TfLiteTensor *output = interpreter.output(0); int8_t vmax = -128; uint32_t max_index = 0; //find the max in the output sensor, its index is our prediction.. for(uint32_t i = 0; i \u003c 10; i++) { if(output-\u003edata.int8[i] \u003e vmax) { vmax = output-\u003edata.int8[i]; max_index = i;\t} } //clear frame for(uint32_t x = 0; x \u003c 28*28; x++) { *((float*)img + x) = 0; } //do whatever you want with the prediction..maybe show it on a screen? In the actual demo whose video is shown above, all the inference is run on a separate FreeRTOS task whereas the UI is rendered on a separate task.\nBut why run Neural Networks on MCUs? You don’t need to.\nMachine learning is just another tool in an engineers toolbox. Some problems are better suited for it, some aren’t.\nWhen we are talking about a resource constraint environment such as a Microcontroller, we have to choose wisely where to effectively use the power of ML.\nThe compute power provided by even the most powerful MCUs on the market today is not enough to run complex image classification networks, But if you choose your battles wisely, you can get away with quite good results.\nSome tasks can simply use DSP and other classification techniques to make predictions which can be faster than running ML inference.\nML shines when we need to combine data from multiple sensors to make a common predictions, which can be difficult to do in traditional way.\nAnyways.. MCU manufacturers are aware of the lack of compute power in current MCUs and are investing in IPs to help accelerate AI workloads on the edge.\nARM has launched Cortex-M85, its latest core which includes Helium SIMD support which will further improve performance, coupled with the Ethos-u65 NPU we might just have enough power in our hands.\nManufacturers such as NXP and STM are also coming our with their own proprietary NPU IPs in general MCU.\nLets see what the future holds…\n","wordCount":"1910","inLanguage":"en","datePublished":"2023-03-02T04:21:11+05:30","dateModified":"2023-03-02T04:21:11+05:30","author":{"@type":"Person","name":"magalsh64"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://qcentlabs.com/posts/ml_on_mcu/"},"publisher":{"@type":"Organization","name":"qcentlabs","logo":{"@type":"ImageObject","url":"http://qcentlabs.com/logo.png"}}}</script></head><body class=dark id=top><header class=header><nav class=nav><div class=logo><a href=http://qcentlabs.com/ accesskey=h title="qcentlabs (Alt + H)">qcentlabs</a>
<span class=logo-switches></span></div><ul id=menu><li><a href=http://qcentlabs.com/about/ title=about><span>about</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://qcentlabs.com/>Home</a>&nbsp;»&nbsp;<a href=http://qcentlabs.com/posts/>Posts</a></div><h1 class=post-title>Machine Learning on Microcontrollers.</h1><div class=post-meta><span title='2023-03-02 04:21:11 +0530 IST'>March 2, 2023</span>&nbsp;·&nbsp;9 min&nbsp;·&nbsp;magalsh64</div></header><div class=post-content><h1 id=the-rise-of-machines>The Rise of Machine(s)<a hidden class=anchor aria-hidden=true href=#the-rise-of-machines>#</a></h1><p><em>&ldquo;The AI revolution in 2023 brought transformative changes to industries and daily life. Intelligent automation and advanced algorithms improved efficiency in manufacturing, healthcare, finance, and transportation. Natural language processing has led to the emergence of sophisticated voice assistants. Breakthroughs in image recognition and sentiment analysis revolutionised fields like autonomous vehicles, cybersecurity, and personalised marketing.&rdquo;</em></p><p>Well, I didn&rsquo;t write any of it, ChatGPT did.</p><p>So today we are going to explore if we can take advantage of machine learning to help build better embedded systems.</p><p>This article is a continuation of a previous blog <a href=/posts/synaptics_hack/>post</a> in which, I hacked a synaptics touchpad.</p><p>We will use the touchpad as a base to get input for our neural network model.</p><p>Machine learning is all about building and training models, which are essentially neural networks, to make predictions about what some input to the model might be.</p><p>This information (the prediction) can then be used to do various cool things.</p><br><center><video width=50% playsinline autoplay muted loop>
<source src=/videos/tflm.mp4 type=video/mp4></video></center><p><em>&ldquo;Infrerence running on an $8 ARM Cortex-M7 MCU on a 28x28 image using LSTM model in under 7ms with more than 96% accuracy.&rdquo;</em></p><br><p>The process of running ML models on a MCU can be divided into three parts:</p><ul><li>Recording data from various sensors to be used as the input to our network.</li><li>Modelling and training the network with the recorded data.</li><li>Deploying and running inference on the trained model using new real world data.</li></ul><p>Although some ML frameworks allow you to train the model on the MCU, most sane people will use a much powerful host computer or a web ML platform (Google Colab) to make and train the NN model.</p><p>How you run the inference of the trained model on the MCU depends on which ML framework you have chosen to use.</p><h2 id=so-how-is-it-done>So, How is it done?<a hidden class=anchor aria-hidden=true href=#so-how-is-it-done>#</a></h2><p>For making and training the model, TensorFlow is used almost exclusively.</p><p>I have used Keras, which gives us an easy to use python interface for accessing the TensorFlow library.</p><p>You can also use Google Colab Platform to make and train the model without having to deal with installing keras and tensorflow locally on your machine.</p><p>For running inference of the trained model, you have many options depending on which MCU you use.</p><p>There are quite a few ML frameworks available for MCUs, some manufacturers provide their owm ML frameworks for running models.</p><p>Some popular ones are:</p><ul><li>TensorFlow Lite for Microcontrollers. (TFLM)</li><li>AIfES</li><li>DeepViewRT (NXP)</li><li>STM32Cube.AI (STM)</li></ul><p>I have used both TFLM and AIfES, both are quite capable but TFLM has more features and support for more types of Ops but requires c++ support and is complex,<br>AIfES on the other hand is quite easy to use and is written in C, but lacks features.</p><p>Also, you can directly import tflite models into TFLM, whereas AIfES requires you to extract weights and biases from your trained model and import them separately which is quite tedious.</p><h2 id=step-1-collect-the-data>Step 1: Collect the data.<a hidden class=anchor aria-hidden=true href=#step-1-collect-the-data>#</a></h2><p>The synaptics touchpad is the sensor that we will use to collect data for our ML demo.</p><p>The touchpad outputs data over PS/2 which is captured by our MCU.</p><p>The touchpad reports us with the absolute position of our finger when we touch it, we treat every position reported to us as a pixel coordinate in an image whose size is given by the resolution of our touchpad.</p><p>Whenever a touch is reported we just fill the pixel coordinate with a value of 1 in our image array.</p><p>This specific model of touchpad has a resolution of near about 5600 x 4600 which is too big for even an average modern single GPU to run real time inference on let alone our MCU, so we need to scale down this resolution to something our MCU can handle.</p><p>For digit recognition, there is a well known dataset of small handwritten digits called MNIST dataset, we will use it as a starting point as it will provide us will a good large pre-tested dataset to train our network on.</p><p>The resolution of images in the MNIST dataset is 28x28, perfectly within the bounds of compute of our MCU, so we will scale down our touchpads 5600x4600 image to a 28x28 image.</p><p>Here are some of the raw samples that i recorded from the touchpad:</p><center><p><img loading=lazy src=/images/ml_on_mcu/raw_samples.png alt="raw samples"></p></center><p>As you can see, the raw points captured by our touchpad when downsampled to a 28x28 pose a bit of a problem for us.</p><ul><li>Firstly, sometimes you can see skipped pixels, these errors can be attributed to the downsampling process and also because the sample rate of our touchpad is not very high, and if we very quickly swipe our finger across the touchpad, we loose some samples.</li><li>Secondly, these raw sample images have too little data in terms of pixel variations, the very narrow strokes of the touchpad samples are good for getting positioning data but do not resemble an actual pen stroke (something our MNIST dataset is based on.)</li></ul><p>Here is an example of what MNIST dataset containes:</p><center><p><img loading=lazy src=/images/ml_on_mcu/mnist_samples.png alt="mnist samples"></p></center><p>You can see they do not match at all, If we train our NN on MNIST and then validate the NN on our raw samples, we will get very poor accuracy.</p><p>Thus we need to do a bit of pre-processing with our raw samples to make them a bit more like MNIST samples.</p><p>In we were to do this the right way, we would be collecting our own samples and making a large dataset for them as that would give us the best accuracy but that is a very time consuming task and thus we are cheating a bit here by using both MNIST which has over 60000 samples combined with some of our own raw samples.</p><p>Here is our pre-processed version of touchpad data samples, this looks good enough for a demo.</p><center><p><img loading=lazy src=/images/ml_on_mcu/processed_samples.png alt="pre-processed samples"></p></center><p>Not perfect, but would do the job. This pre-processing is done in real-time on MCU by applying a 3x3 averaging kernel.</p><p>Now we collect and save a lot of these pre-processed images, our MCU simply sends them over USART as a C array and we have a program on host computer that writes this data to a CSV file which can then be used to train our neural network model.</p><h2 id=step-2-make-and-train-the-model>Step 2: Make and Train the model.<a hidden class=anchor aria-hidden=true href=#step-2-make-and-train-the-model>#</a></h2><p>I use google colab to test and train models.</p><p>Here is the python script for the final version of the model which uses LSTM.</p><pre tabindex=0><code>import tensorflow as tf
from tensorflow import keras
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

print(&#34;using tf version: &#34;, tf.__version__)

dataset = pd.read_csv(&#34;drive/MyDrive/data/data_fat.csv&#34;)

x_train_custom = dataset.copy()
y_train_custom = np.array(x_train_custom.pop(&#39;0&#39;))
x_train_custom = np.array(x_train_custom)
x_train_custom = np.array(x_train_custom,dtype=np.float32)

(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
x_train = x_train.flatten()
x_train = x_train.reshape(60000,784)
x_train = x_train/255
x_train = np.array(x_train,dtype=np.float32)

x_train = np.append(x_train,x_train_custom)
y_train = np.append(y_train,y_train_custom)

x_train = x_train.reshape(60542,784)

dataset = pd.read_csv(&#34;drive/MyDrive/data/data_fat.csv&#34;)

x_test = dataset.copy()
y_test = np.array(x_test.pop(&#39;0&#39;))
x_test = np.array(x_test)
x_test = np.array(x_test,dtype=np.float32)

model = tf.keras.Sequential()
model.add(tf.keras.layers.Input(784,batch_size=1,dtype=tf.float32))
model.add(tf.keras.layers.Reshape((28,28)))
model.add(tf.keras.layers.LSTM(20,return_sequences=True))
# model.add(tf.keras.layers.Conv2D(filters=8,kernel_size=3,padding=&#39;same&#39;,activation=&#39;relu&#39;))
# model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2),padding=&#39;same&#39;))
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(128))
model.add(tf.keras.layers.LeakyReLU(alpha=0.01))
model.add(tf.keras.layers.Dense(10))
model.add(tf.keras.layers.Activation(&#39;softmax&#39;))

loss_fn = keras.losses.SparseCategoricalCrossentropy()

model.compile(optimizer=&#39;adam&#39;,loss=loss_fn,metrics=[&#34;accuracy&#34;])

model.fit(x_train,y_train,epochs=5,shuffle=True,validation_data=(x_test,y_test))

model.save(&#34;drive/MyDrive/data/tp.model&#34;)

def representative_dataset():
    for data in x_train[:100]:
      yield [data.reshape(1, 28, 28)]

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.int8
converter.inference_output_type = tf.int8
tflite_model = converter.convert()

# Save the model.
with open(&#39;drive/MyDrive/data/model.tflite&#39;, &#39;wb&#39;) as f:
  f.write(tflite_model)
</code></pre><p>Few things to note here,</p><p>We use google drive to host our custom dataset in a csv file, which we then read from and combine the custom data with
the one from MNIST dataset.</p><p>I tried 3 different models each with different pros and cons.</p><p>First a simple FFN with 2-3 Dense layers, which was very fast to run inference on(5ms) and had small size but most of the time had overfitting issues which led to poor real-world accuracy.</p><p>Then 1-2 Conv2D layers model was used instead of simple Dense layer, which offered high accuracy among real world input but was very slow to infer(0.5-3 seconds) and was huge in size (2-4MB).</p><p>Finally a single LSTM layer was used which gave us high enough accuracy(96%) and was quicker to run inference on (~150ms) and had moderate size(400kB);</p><p>All of the above performance figures were on non optimized models running on FP32 data.</p><p>Huge performance and memory gains were seen when converting the model to run on INT8 instead of FP32.</p><p>This is because TFLM can utilise the CMSIS-NN library which uses the native fixed point integer SIMD instructions(DSP extentions) present in Arm Cortex M7 and M4, which can help accelerate a lot of operations.</p><p>LSTM models inference time decreased to 7ms from 150ms, and size became ~80k from ~330kb.</p><p>Accuracy remained almost the same as humanly perceived,</p><p>The output of this training process gave us our <strong>model.tflite</strong> file which was then converted to a C array using xxd tool.</p><pre tabindex=0><code>    xxd -i model.tflite &gt; model.h
</code></pre><p>This header file was included into our MCU project.</p><h2 id=step-3-run-inference-on-the-trained-model>Step 3: Run inference on the trained model.<a hidden class=anchor aria-hidden=true href=#step-3-run-inference-on-the-trained-model>#</a></h2><p>A condensed version of the code that runs on the MCU is shown below.</p><pre tabindex=0><code>#include &#34;model.h&#34;


const int tensor_arena_size = 32768 * 2;

uint8_t tensor_arena[tensor_arena_size];



.
.
.

//Initialise TFLM

tflite::MicroErrorReporter micro_error_reporter;

tflite::ErrorReporter *error_reporter = &amp;micro_error_reporter;

const tflite::Model *model = tflite::GetModel(model_tflite);

tflite::AllOpsResolver resolver;

tflite::MicroInterpreter interpreter(model,resolver,tensor_arena,tensor_arena_size,error_reporter);

interpreter.AllocateTensors();



.
.
.

//somewhere in the code where PS/2 data is captured and pre-processed and stored in a array of floats

.
.
.

//Runs in a loop..

TfLiteTensor *input = interpreter.input(0);

//load our pre-processed sample data into the tensor
for(uint32_t i = 0; i &lt; 784; i++)
    input-&gt;data.int8[i] = (*((float*)img + i) * 255) - 128;

//run the inference 
interpreter.Invoke();

TfLiteTensor *output = interpreter.output(0);

int8_t vmax = -128;
uint32_t max_index = 0;

//find the max in the output sensor, its index is our prediction..
for(uint32_t i = 0; i &lt; 10; i++)
{
    if(output-&gt;data.int8[i] &gt; vmax)
    {
        vmax = output-&gt;data.int8[i];
        max_index = i;		
    }
}

//clear frame
for(uint32_t x = 0; x &lt; 28*28; x++)
{
    *((float*)img + x) = 0;
}

//do whatever you want with the prediction..maybe show it on a screen?
</code></pre><p>In the actual demo whose video is shown above, all the inference is run on a separate FreeRTOS task whereas the UI is rendered on a separate task.</p><h2 id=but-why-run-neural-networks-on-mcus>But why run Neural Networks on MCUs?<a hidden class=anchor aria-hidden=true href=#but-why-run-neural-networks-on-mcus>#</a></h2><p>You don&rsquo;t need to.</p><p>Machine learning is just another tool in an engineers toolbox. Some problems are better suited for it, some aren&rsquo;t.</p><p>When we are talking about a resource constraint environment such as a Microcontroller, we have to choose wisely where to effectively use the power of ML.</p><p>The compute power provided by even the most powerful MCUs on the market today is not enough to run complex image classification networks, But if you choose your battles wisely, you can get away with quite good results.</p><p>Some tasks can simply use DSP and other classification techniques to make predictions which can be faster than running ML inference.</p><p>ML shines when we need to combine data from multiple sensors to make a common predictions, which can be difficult to do in traditional way.</p><p>Anyways.. MCU manufacturers are aware of the lack of compute power in current MCUs and are investing in IPs to help accelerate AI workloads on the edge.</p><p>ARM has launched Cortex-M85, its latest core which includes Helium SIMD support which will further improve performance, coupled with the Ethos-u65 NPU we might just have enough
power in our hands.</p><p>Manufacturers such as NXP and STM are also coming our with their own proprietary NPU IPs in general MCU.</p><p>Lets see what the future holds&mldr;</p></div><footer class=post-footer><nav class=paginav><a class=next href=http://qcentlabs.com/posts/gpu_in_mcu/><span class=title>Next Page »</span><br><span>Exploring GPUs in Microcontrollers.</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Machine Learning on Microcontrollers. on twitter" href="https://twitter.com/intent/tweet/?text=Machine%20Learning%20on%20Microcontrollers.&amp;url=http%3a%2f%2fqcentlabs.com%2fposts%2fml_on_mcu%2f&amp;hashtags="><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Machine Learning on Microcontrollers. on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2fqcentlabs.com%2fposts%2fml_on_mcu%2f&amp;title=Machine%20Learning%20on%20Microcontrollers.&amp;summary=Machine%20Learning%20on%20Microcontrollers.&amp;source=http%3a%2f%2fqcentlabs.com%2fposts%2fml_on_mcu%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Machine Learning on Microcontrollers. on reddit" href="https://reddit.com/submit?url=http%3a%2f%2fqcentlabs.com%2fposts%2fml_on_mcu%2f&title=Machine%20Learning%20on%20Microcontrollers."><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Machine Learning on Microcontrollers. on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2fqcentlabs.com%2fposts%2fml_on_mcu%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Machine Learning on Microcontrollers. on whatsapp" href="https://api.whatsapp.com/send?text=Machine%20Learning%20on%20Microcontrollers.%20-%20http%3a%2f%2fqcentlabs.com%2fposts%2fml_on_mcu%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Machine Learning on Microcontrollers. on telegram" href="https://telegram.me/share/url?text=Machine%20Learning%20on%20Microcontrollers.&amp;url=http%3a%2f%2fqcentlabs.com%2fposts%2fml_on_mcu%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2023 <a href=http://qcentlabs.com/>qcentlabs</a></span>
<span></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script></body></html>